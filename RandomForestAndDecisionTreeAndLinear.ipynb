{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Dataframes\n",
    "df_lu = pd.read_csv('Luxembourg_new.csv')\n",
    "df_de = pd.read_csv('Deutschland_new.csv')\n",
    "df_fr = pd.read_csv('Frankreich_new.csv')\n",
    "df_be = pd.read_csv('Belgien_new.csv')\n",
    "\n",
    "df_lu = df_lu.sample(frac=1, random_state=0)\n",
    "df_de = df_de.sample(frac=1, random_state=0)\n",
    "df_fr = df_fr.sample(frac=1, random_state=0)\n",
    "df_be = df_be.sample(frac=1, random_state=0)\n",
    "\n",
    "#List of Attributes relevant for Dataframes\n",
    "fe_lu = [\"Grundstücksfläche\",\"Badezimmer\", \"Schlafzimmer\",\"Haus\", \"Distanz\",\"Garten\",\"Parkplätze\"]\n",
    "fe_de = [\"Grundstücksfläche\",\"Schlafzimmer\",\"DistanzKöln\",\"Badezimmer\",\"Baujahr\"]\n",
    "fe_fr = [\"Grundstücksfläche\",\"Badezimmer\",\"DistanzThionville\",\"Garten\",\"Haus\"]\n",
    "fe_be = [\"Grundstücksfläche\",\"Badezimmer\", \"Schlafzimmer\",\"Haus\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Decomposition into principal componentens\n",
    "pca_lu = PCA(5)\n",
    "pca_de = PCA(7)\n",
    "pca_fr = PCA(4)\n",
    "pca_be = PCA(3)\n",
    "\n",
    "#Attribute aus den Datensätzen entfernen\n",
    "X_lu = df_lu.drop(['Stadt','Wohnung','Kaufpreis','Garten','Bevölkerung','Parkplätze'], axis = 1)\n",
    "X_de = df_de.drop(['Stadt','Kaufpreis','Parkplätze','DistanzSaarbrücken','Wohnung'], axis = 1)\n",
    "X_fr = df_fr.drop(['Stadt','Wohnung','Kaufpreis','Bevölkerung','Parkplätze','DistanzThionville','DistanzMetz'], axis = 1)\n",
    "X_be = df_be.drop(['Stadt','Wohnung','Kaufpreis','Garten','Bevölkerung','DistanzNamur','Parkplätze'], axis = 1)\n",
    "\n",
    "#Fit Data to Scaler and scale Data(transform)\n",
    "X0_lu = scaler.fit_transform(X_lu)\n",
    "X0_de = scaler.fit_transform(X_de)\n",
    "X0_fr = scaler.fit_transform(X_fr)\n",
    "X0_be = scaler.fit_transform(X_be)\n",
    "\n",
    "#fit PCA and transform decomposition onto dataset\n",
    "X1_lu = pca_lu.fit_transform(X0_lu)\n",
    "X1_de = pca_de.fit_transform(X0_de)\n",
    "X1_fr = pca_fr.fit_transform(X0_fr)\n",
    "X1_be = pca_be.fit_transform(X0_be)\n",
    "\n",
    "#Drop target variable\n",
    "y_lu = df_lu['Kaufpreis']\n",
    "y_de = df_de['Kaufpreis']\n",
    "y_fr = df_fr['Kaufpreis']\n",
    "y_be = df_be['Kaufpreis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luxemburg\n",
      "MAE without PCA: 0.429\n",
      "R2 without PCA: 0.612\n",
      "RMSE without PCA: 0.621\n",
      "Deutschland\n",
      "MAE without PCA: 0.505\n",
      "R2 without PCA: 0.167\n",
      "RMSE without PCA: 0.729\n",
      "Frankreich\n",
      "MAE without PCA: 0.426\n",
      "R2 without PCA: 0.477\n",
      "RMSE without PCA: 0.690\n",
      "Belgien\n",
      "MAE without PCA: 0.378\n",
      "R2 without PCA: 0.533\n",
      "RMSE without PCA: 0.672\n",
      "Luxemburg\n",
      "MAE with PCA: 0.430\n",
      "R2 with PCA: 0.609\n",
      "RMSE with PCA: 0.624\n",
      "Deutschland\n",
      "MAE with PCA: 0.506\n",
      "R2 with PCA: 0.214\n",
      "RMSE with PCA: 0.739\n",
      "Frankreich\n",
      "MAE with PCA: 0.493\n",
      "R2 with PCA: 0.438\n",
      "RMSE with PCA: 0.723\n",
      "Belgien\n",
      "MAE with PCA: 0.417\n",
      "R2 with PCA: 0.401\n",
      "RMSE with PCA: 0.762\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=5, n_repeats=100, random_state=1)\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "Y_std_lu = statistics.stdev(y_lu)\n",
    "Y_std_be = statistics.stdev(y_be)\n",
    "Y_std_de = statistics.stdev(y_de)\n",
    "Y_std_fr = statistics.stdev(y_fr)\n",
    "\n",
    "\n",
    "#No PCA\n",
    "mae_lu = cross_val_score(model, X_lu, y_lu,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_lu = cross_val_score(model, X_lu, y_lu,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_lu = cross_val_score(model, X_lu, y_lu,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "\n",
    "mae_lu = mae_lu / Y_std_lu\n",
    "rmse_lu = rmse_lu / Y_std_lu\n",
    "\n",
    "print(\"Luxemburg\")\n",
    "print('MAE without PCA: %.3f' % (abs(np.mean(mae_lu))))\n",
    "print('R2 without PCA: %.3f' % ((np.mean(r2_lu))))\n",
    "print('RMSE without PCA: %.3f' % (abs(np.mean(rmse_lu))))\n",
    "mae_de = cross_val_score(model, X_de, y_de,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_de = cross_val_score(model, X_de, y_de,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_de = cross_val_score(model, X_de, y_de,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "\n",
    "mae_de = mae_de / Y_std_de\n",
    "rmse_de = rmse_de / Y_std_de\n",
    "print(\"Deutschland\")\n",
    "print('MAE without PCA: %.3f' % (abs(np.mean(mae_de))))\n",
    "print('R2 without PCA: %.3f' % ((np.mean(r2_de))))\n",
    "print('RMSE without PCA: %.3f' % (abs(np.mean(rmse_de))))\n",
    "mae_fr = cross_val_score(model, X_fr, y_fr,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_fr = cross_val_score(model, X_fr, y_fr,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_fr = cross_val_score(model, X_fr, y_fr,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "\n",
    "mae_fr = mae_fr / Y_std_fr\n",
    "rmse_fr = rmse_fr / Y_std_fr\n",
    "print(\"Frankreich\")\n",
    "print('MAE without PCA: %.3f' % (abs(np.mean(mae_fr))))\n",
    "print('R2 without PCA: %.3f' % ((np.mean(r2_fr))))\n",
    "print('RMSE without PCA: %.3f' % (abs(np.mean(rmse_fr))))\n",
    "mae_be = cross_val_score(model, X_be, y_be,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_be = cross_val_score(model, X_be, y_be,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_be = cross_val_score(model, X_be, y_be,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "mae_be= mae_be/ Y_std_be\n",
    "rmse_be = rmse_be/ Y_std_be\n",
    "print(\"Belgien\")\n",
    "print('MAE without PCA: %.3f' % (abs(np.mean(mae_be))))\n",
    "print('R2 without PCA: %.3f' % ((np.mean(r2_be))))\n",
    "print('RMSE without PCA: %.3f' % (abs(np.mean(rmse_be))))\n",
    "\n",
    "#PCA\n",
    "mae_lu = cross_val_score(model, X1_lu, y_lu,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_lu = cross_val_score(model, X1_lu, y_lu,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_lu = cross_val_score(model, X1_lu, y_lu,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "mae_lu = mae_lu / Y_std_lu\n",
    "rmse_lu = rmse_lu / Y_std_lu\n",
    "print(\"Luxemburg\")\n",
    "print('MAE with PCA: %.3f' % (abs(np.mean(mae_lu))))\n",
    "print('R2 with PCA: %.3f' % ((np.mean(r2_lu))))\n",
    "print('RMSE with PCA: %.3f' % (abs(np.mean(rmse_lu))))\n",
    "mae_de = cross_val_score(model, X1_de, y_de,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_de = cross_val_score(model, X1_de, y_de,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_de = cross_val_score(model, X1_de, y_de,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "mae_de = mae_de / Y_std_de\n",
    "rmse_de = rmse_de / Y_std_de\n",
    "print(\"Deutschland\")\n",
    "print('MAE with PCA: %.3f' % (abs(np.mean(mae_de))))\n",
    "print('R2 with PCA: %.3f' % ((np.mean(r2_de))))\n",
    "print('RMSE with PCA: %.3f' % (abs(np.mean(rmse_de))))\n",
    "mae_fr = cross_val_score(model, X1_fr, y_fr,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_fr = cross_val_score(model, X1_fr, y_fr,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_fr = cross_val_score(model, X1_fr, y_fr,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "mae_fr = mae_fr / Y_std_fr\n",
    "rmse_fr = rmse_fr / Y_std_fr\n",
    "print(\"Frankreich\")\n",
    "print('MAE with PCA: %.3f' % (abs(np.mean(mae_fr))))\n",
    "print('R2 with PCA: %.3f' % ((np.mean(r2_fr))))\n",
    "print('RMSE with PCA: %.3f' % (abs(np.mean(rmse_fr))))\n",
    "mae_be = cross_val_score(model, X1_be, y_be,scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "r2_be = cross_val_score(model, X1_be, y_be,scoring=\"r2\", cv=cv, n_jobs=-1)\n",
    "rmse_be = cross_val_score(model, X1_be, y_be,scoring=\"neg_root_mean_squared_error\", cv=cv, n_jobs=-1)\n",
    "mae_be = mae_be/ Y_std_be\n",
    "rmse_be = rmse_be / Y_std_be\n",
    "print(\"Belgien\")\n",
    "print('MAE with PCA: %.3f' % (abs(np.mean(mae_be))))\n",
    "print('R2 with PCA: %.3f' % ((np.mean(r2_be))))\n",
    "print('RMSE with PCA: %.3f' % (abs(np.mean(rmse_be))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features\n",
    "fe_lu = [\"Baujahr\", \"Grundstücksfläche\", \"Schlafzimmer\",\"Bevölkerung\", \"Distanz\"]\n",
    "fe_de = [\"Baujahr\", \"Grundstücksfläche\",\"Bevölkerung\",\"DistanzKöln\",\"DistanzFrankfurt\",\"DistanzSaarbrücken\"]\n",
    "fe_fr = [\"Baujahr\", \"Grundstücksfläche\",\"Badezimmer\",\"DistanzThionville\",\"DistanzMetz\",\"DistanzLuxemburg\"]\n",
    "fe_be = [\"Baujahr\", \"Grundstücksfläche\", \"Schlafzimmer\",\"Parkplätze\",\"DistanzLuxemburg\",\"DistanzNamur\",\"DistanzMaastricht\",\"DistanzBrüssel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeRegression(df,features,components,dopca = False):\n",
    "    df = df.sample(frac=1, random_state=0)\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(components)    \n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[['Kaufpreis']]\n",
    "\n",
    "    X0 = scaler.fit_transform(X)\n",
    "    X1 = pca.fit_transform(X0)\n",
    "    std_Y = np.std(y)\n",
    "    \n",
    "    param_grid = {'max_depth': np.arange(1,40,3)}\n",
    "    tree = GridSearchCV(DecisionTreeRegressor(), param_grid,return_train_score=False)\n",
    "    #find best height for decision tree\n",
    "    tree.fit(X,y)\n",
    "    if(dopca == True):\n",
    "        tree.fit(X1,y)\n",
    "    tree_final = DecisionTreeRegressor(max_depth=tree.best_params_['max_depth'])\n",
    "\n",
    "\n",
    "    if(dopca == True):\n",
    "        #calculate mae, mse and r2 scores by k-fold cross validation\n",
    "        mae_scores = cross_val_score(tree_final, X1, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        mse_scores = cross_val_score(tree_final, X1, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "        r2_scores = cross_val_score(tree_final, X1, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        \n",
    "        return makeScoresCV(mae_scores,mse_scores,r2_scores,std_Y)\n",
    "        \n",
    "    else:\n",
    "        mae_scores = cross_val_score(tree_final, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        mse_scores = cross_val_score(tree_final, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "        r2_scores = cross_val_score(tree_final, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        return makeScoresCV(mae_scores,mse_scores,r2_scores, std_Y)\n",
    "\n",
    "def makeScoresCV(scores,scores2,scores3, std_Y): \n",
    "    # convert scores to positive\n",
    "    scores = absolute(scores)\n",
    "    scores2 = absolute(scores2)\n",
    "    \n",
    "    # summarize the result\n",
    "    s_mean =  mean(scores)/std_Y\n",
    "    s_mean2 = mean(scores2)\n",
    "    s_mean3 = mean(scores3)\n",
    "    \n",
    "    return s_mean,np.sqrt(s_mean2) / std_Y,s_mean3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUXEMBURG\n",
      "NO PCA\n",
      "mae : Kaufpreis    0.248178\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.501479\n",
      "dtype: float64\n",
      "r2 : 0.7475409808866266\n",
      "PCA\n",
      "mae : Kaufpreis    0.258324\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.55374\n",
      "dtype: float64\n",
      "r2 : 0.6945635105628657\n",
      "DEUTSCHLAND\n",
      "NO PCA\n",
      "mae : Kaufpreis    0.415552\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.678533\n",
      "dtype: float64\n",
      "r2 : 0.27571122006270127\n",
      "PCA\n",
      "mae : Kaufpreis    0.471355\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.76598\n",
      "dtype: float64\n",
      "r2 : 0.010611374412977779\n",
      "FRANKREICH\n",
      "NO PCA\n",
      "mae : Kaufpreis    0.342309\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.782714\n",
      "dtype: float64\n",
      "r2 : 0.3704963867568549\n",
      "PCA\n",
      "mae : Kaufpreis    0.393094\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.833393\n",
      "dtype: float64\n",
      "r2 : 0.2707040579218146\n",
      "BELGIEN\n",
      "NO PCA\n",
      "mae : Kaufpreis    0.277781\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.696282\n",
      "dtype: float64\n",
      "r2 : 0.503901269775555\n",
      "PCA\n",
      "mae : Kaufpreis    0.296801\n",
      "dtype: float64\n",
      "rmse : Kaufpreis    0.723106\n",
      "dtype: float64\n",
      "r2 : 0.46153385635556615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mae, rmse, r2 = decisionTreeRegression(df_lu,fe_lu,3)\n",
    "maeb, rmseb, r2b = decisionTreeRegression(df_lu,fe_lu,3,dopca = True)\n",
    "print(\"LUXEMBURG\")\n",
    "print(\"NO PCA\")\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"PCA\")\n",
    "print(\"mae : \" + str(maeb))\n",
    "print(\"rmse : \" + str(rmseb))\n",
    "print(\"r2 : \" + str(r2b))\n",
    "\n",
    "mae, rmse, r2 = decisionTreeRegression(df_de,fe_de,4)\n",
    "maeb, rmseb, r2b = decisionTreeRegression(df_de,fe_de,4,dopca = True)\n",
    "print(\"DEUTSCHLAND\")\n",
    "print(\"NO PCA\")\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"PCA\")\n",
    "print(\"mae : \" + str(maeb))\n",
    "print(\"rmse : \" + str(rmseb))\n",
    "print(\"r2 : \" + str(r2b))\n",
    "\n",
    "mae, rmse, r2 = decisionTreeRegression(df_fr,fe_fr,5)\n",
    "maeb, rmseb, r2b = decisionTreeRegression(df_fr,fe_fr,5,dopca = True)\n",
    "print(\"FRANKREICH\")\n",
    "print(\"NO PCA\")\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"PCA\")\n",
    "print(\"mae : \" + str(maeb))\n",
    "print(\"rmse : \" + str(rmseb))\n",
    "print(\"r2 : \" + str(r2b))\n",
    "\n",
    "\n",
    "mae, rmse, r2 = decisionTreeRegression(df_be,fe_be,6)\n",
    "maeb, rmseb, r2b = decisionTreeRegression(df_be,fe_be,6,dopca = True)\n",
    "print(\"BELGIEN\")\n",
    "print(\"NO PCA\")\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"PCA\")\n",
    "print(\"mae : \" + str(maeb))\n",
    "print(\"rmse : \" + str(rmseb))\n",
    "print(\"r2 : \" + str(r2b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lu = PCA(4)\n",
    "pca_de = PCA(5)\n",
    "pca_fr = PCA(8)\n",
    "pca_be = PCA(7)\n",
    "\n",
    "df_lu = df_lu.drop(['Haus','Garten','Parkplätze','Stadt','Wohnung'],axis = 1)\n",
    "df_de = df_de.drop(['Garten','Haus','Stadt','Wohnung'],axis = 1)\n",
    "df_fr = df_fr.drop(['Garten','Haus','Stadt','Wohnung'],axis = 1)\n",
    "df_be = df_be.drop(['Haus','Garten','Stadt','Wohnung'],axis = 1)\n",
    "\n",
    "X_lu = df_lu.drop('Kaufpreis', axis = 1)\n",
    "X_de = df_de.drop('Kaufpreis', axis = 1)\n",
    "X_fr = df_fr.drop('Kaufpreis', axis = 1)\n",
    "X_be = df_be.drop('Kaufpreis', axis = 1)\n",
    "\n",
    "Y_lu = df_lu['Kaufpreis']\n",
    "Y_de = df_de['Kaufpreis']\n",
    "Y_fr = df_fr['Kaufpreis']\n",
    "Y_be = df_be['Kaufpreis']\n",
    "\n",
    "X_std_lu = scaler.fit_transform(X_lu)\n",
    "X_std_de = scaler.fit_transform(X_de)\n",
    "X_std_fr = scaler.fit_transform(X_fr)\n",
    "X_std_be = scaler.fit_transform(X_be)\n",
    "\n",
    "X_cd_lu = pca_lu.fit_transform(X_std_lu)\n",
    "X_cd_de = pca_de.fit_transform(X_std_de)\n",
    "X_cd_fr = pca_fr.fit_transform(X_std_fr)\n",
    "X_cd_be = pca_be.fit_transform(X_std_be)\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 15, num = 15)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(best_random, test_features, test_labels):\n",
    "    mae_scores = cross_val_score(best_random, test_features, test_labels, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    mse_scores = cross_val_score(best_random, test_features, test_labels, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    r2_scores = cross_val_score(best_random, test_features, test_labels, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    mse_scores = absolute(mse_scores)\n",
    "    mae_scores = absolute(mae_scores)\n",
    "    \n",
    "    stdev_Y = statistics.stdev(test_labels)\n",
    "\n",
    "    s_mean = mean(mae_scores)/stdev_Y\n",
    "    s_mean2 = mean(r2_scores)\n",
    "    s_mean3 = mean(mse_scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return s_mean,s_mean2,np.sqrt(s_mean3)/stdev_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luxemburg\n",
      "mae : 0.15113369340066513\n",
      "rmse : 0.34661337985011414\n",
      "r2 : 0.8811739997800905\n",
      "mae : 0.187358032133793\n",
      "rmse : 0.4188333666363122\n",
      "r2 : 0.8252503139737608\n",
      "Deutschland\n",
      "mae : 0.3076054350469032\n",
      "rmse : 0.5407762058406258\n",
      "r2 : 0.6088045668335084\n",
      "mae : 0.47072246229881604\n",
      "rmse : 0.8104049308636934\n",
      "r2 : 0.22283417862446003\n",
      "Frankreich\n",
      "mae : 0.2664985047534866\n",
      "rmse : 0.5973142393912843\n",
      "r2 : 0.6414788473090939\n",
      "mae : 0.31561025280665683\n",
      "rmse : 0.6473230690312649\n",
      "r2 : 0.576015684341518\n",
      "Belgien\n",
      "mae : 0.24696795103580985\n",
      "rmse : 0.5252398535537675\n",
      "r2 : 0.7221656312890274\n",
      "mae : 0.2684235350630537\n",
      "rmse : 0.5905210036828972\n",
      "r2 : 0.6475712528738298\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, n_jobs = -1)\n",
    "print(\"Luxemburg\")\n",
    "rf_random.fit(X_lu, Y_lu)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_lu, Y_lu)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "\n",
    "\n",
    "rf_random.fit(X_cd_lu, Y_lu)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_cd_lu, Y_lu)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"Deutschland\")\n",
    "\n",
    "rf_random.fit(X_de, Y_de)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_de, Y_de)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "\n",
    "rf_random.fit(X_cd_de, Y_de)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random,X_cd_de,Y_de)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"Frankreich\")\n",
    "\n",
    "rf_random.fit(X_fr, Y_fr)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_fr, Y_fr)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "\n",
    "rf_random.fit(X_cd_fr, Y_fr)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_cd_fr,Y_fr)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "print(\"Belgien\")\n",
    "\n",
    "rf_random.fit(X_be, Y_be)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_be, Y_be)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "\n",
    "rf_random.fit(X_cd_be, Y_be)\n",
    "best_random = rf_random.best_estimator_\n",
    "mae,r2,rmse = evaluate(best_random, X_cd_be, Y_be)\n",
    "print(\"mae : \" + str(mae))\n",
    "print(\"rmse : \" + str(rmse))\n",
    "print(\"r2 : \" + str(r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2020_env",
   "language": "python",
   "name": "2020_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
